# ğŸ§¬ Breast Cancer Classification

Este proyecto aplica algoritmos de Machine Learning para predecir si una muestra de tejido mamario es **benigna** o **maligna**, utilizando el dataset de Breast Cancer Wisconsin. Se entrenaron y compararon tres modelos de clasificaciÃ³n supervisada con especial atenciÃ³n a la mÃ©trica **balanced accuracy**, adecuada en escenarios con posible desbalance de clases.

---

## ğŸ“‚ Dataset

- **Variable objetivo:** ClasificaciÃ³n del tumor (2: benigno, 4: maligno)

---

## âš™ï¸ Modelos utilizados

- ğŸ”µ RegresiÃ³n LogÃ­stica
- ğŸŸ¢ Support Vector Machine (SVM) lineal
- ğŸ”´ Random Forest

Cada modelo fue evaluado con **validaciÃ³n cruzada 10-fold** utilizando la mÃ©trica **balanced accuracy** para asegurar una evaluaciÃ³n equilibrada entre clases.

---

## ğŸ“Š Resultados

| Modelo              | Balanced Accuracy |
|---------------------|-------------------|
| RegresiÃ³n LogÃ­stica | 0.97              |
| SVM lineal          | 0.97              |
| Random Forest       | 0.95              |

> ğŸ” RegresiÃ³n LogÃ­stica y SVM lineal obtuvieron el mejor desempeÃ±o. Esta coincidencia se debe a que ambos son clasificadores lineales y el dataset presenta una clara separaciÃ³n entre clases. Random Forest no superÃ³ a los modelos lineales, posiblemente por una leve sobreajuste o por la ausencia de relaciones no lineales fuertes.

---

## ğŸ“ˆ DistribuciÃ³n del Balanced Accuracy

Se graficÃ³ la distribuciÃ³n del balanced accuracy usando estimaciÃ³n de densidad (KDE), junto con la curtosis para evaluar estabilidad.

Todos los modelos presentan **curtosis negativa** (platicÃºrtica), lo que indica una dispersiÃ³n ligeramente mayor en sus rendimientos, pero sin extremos. Esto sugiere que el desempeÃ±o es **estable y confiable**.

![DistribuciÃ³n del Balanced Accuracy](imagen1.png)

---

## ğŸ“Œ Conclusiones

- Todos los modelos lograron un balanced accuracy superior al 95%, lo que indica alta capacidad predictiva.
- Modelos simples como la **RegresiÃ³n LogÃ­stica** y el **SVM lineal** fueron tan eficaces como el Random Forest, lo que refuerza su valor en contextos clÃ­nicos donde la interpretabilidad es importante.
- El anÃ¡lisis de la curtosis revela que el rendimiento es estable, sin valores extremos que comprometan la confiabilidad.

---

## âœ… Recomendaciones

- Priorizar **modelos interpretables** como RegresiÃ³n LogÃ­stica si se busca transparencia clÃ­nica.
- Evaluar tambiÃ©n otras mÃ©tricas: **precisiÃ³n, recall, F1-score, curva ROC-AUC**.
- Visualizar la **matriz de confusiÃ³n** para detectar errores relevantes.
- Realizar **ajuste de hiperparÃ¡metros con cuidado**, ya que el rendimiento ya es estable.
- Documentar versiones de los datos y modelos para asegurar **reproducibilidad**.

---

## ğŸš€ Autor

**Diego Arroyo**  
ğŸ“§ diegojulioarroyo@gmail.com  
ğŸ”— [Mi LinkedIn](https://www.linkedin.com/in/diego-arroyo-b2153b229/) 
